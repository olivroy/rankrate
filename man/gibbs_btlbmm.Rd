% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gibbs_btlbmm.R
\name{gibbs_btlbmm}
\alias{gibbs_btlbmm}
\title{Gibbs Sampling of a BTL-B Mixture Model model}
\usage{
gibbs_btlbmm(
  Pi,
  X,
  M,
  I,
  J,
  Pi_full = NULL,
  num_iter = 1000,
  sigma = NULL,
  p0 = NULL,
  theta0 = NULL,
  seed = NULL,
  adapt_par = c(100, 50, 0.5, 0.5),
  thin = 1,
  verbose = FALSE,
  K = 1,
  alpha0 = 1,
  a = 1,
  b = 1,
  gamma1 = 1,
  gamma2 = 0
)
}
\arguments{
\item{Pi}{Matrix of partial or complete rankings, one row per ranking.}

\item{X}{Matrix of ratings, one row per judge and one column per object.}

\item{M}{Numeric specifying maximum (=worst quality) integer rating.}

\item{I}{Numeric specifying number of judges}

\item{J}{Numeric specifying number of objects}

\item{Pi_full}{Matrix of objects considered when formulating each ranking (to account for groupwise comparisons). Should have same number of rows as Pi, and first entries of each row should match Pi. For example, if a judge considers obejcts 1,2,3,4 and provides the top-2 ranking 1<2, then Pi should have a row with entries 1,2 and Pi_full should have a row with entries 1,2,3,4.}

\item{num_iter}{Number of Gibbs iterations before returning results (default=1000).}

\item{sigma}{Covariance matrix of transformed parameters to sample, for use in restarting the Gibbs sampler after some prior function call. If null, starts with small values and independent structure (default=NULL).}

\item{p0}{Starting object quality parameter values for the algorithm. (default=NULL).}

\item{theta0}{Starting consensus scale parameter values for the algorithm. (default=NULL)}

\item{seed}{Random seed for replicability}

\item{adapt_par}{Vector of four values: (1) first iteration on which to begin covariance adaptation, (2) how many iterations between updates, (3) proportion of previous iterations to use when updating, and (4) proportion of total iterations before stopping updating.}

\item{thin}{Numeric specifying thinning (e.g., 10 means every tenth iteration is retained).}

\item{verbose}{Boolean specifying if iteration information should be printed while function runs.}

\item{K}{Integer specifying number of latent classes (default = 1, i.e., no latent classes)}

\item{alpha0}{Numeric or vector specifying hyperparameters of Dirichlet prior on latent classes. If K>1 and alpha0 is a single number, alpha0 becomes rep(alpha0,K). Default is a flat (uninformative) prior that corresponds to MLE.}

\item{a}{Numeric specifying first hyperparameter on Beta(a,b) prior on each p_jk. Default is a flat (uninformative) prior that corresponds to MLE.}

\item{b}{Numeric specifying second hyperparameter on Beta(a,b) prior on each p_jk. Default is a flat (uninformative) prior that corresponds to MLE.}

\item{gamma1}{Numeric specifying first hyperparameter on Gamma(gamma1,gamma2) prior on each theta_k. Default is a flat (uninformative) prior that corresponds to MLE.}

\item{gamma2}{Numeric specifying second hyperparameter on Gamma(gamma1,gamma2) prior on each theta_k. Default is a flat (uninformative) prior that corresponds to MLE.}
}
\value{
List of estimated parameters (alpha,p,theta,Z).
}
\description{
This function samples approximately from the posterior of a Bradley-Terry-Luce-Binomial distribution with potentially K mixture components via an adaptive Metropolis-Hastings-within-Gibbs algorithm.
}
\examples{
Pi <- matrix(c(1,2,3,4,5,2,1,NA,NA,NA),byrow=TRUE,nrow=2)
Pi_full <- matrix(c(1,2,3,4,5,2,1,3,4,NA),byrow=TRUE,nrow=2)
X <- matrix(c(0,1,2,3,4,1,2,2,5,5),byrow=TRUE,nrow=2)
gibbs_btlbmm(Pi=Pi,X=X,M=6,I=2,J=5,num_iter=100)
gibbs_btlbmm(Pi=Pi,X=X,M=6,I=2,J=5,a=5,b=1,gamma1=10,gamma2=1,num_iter=100)
 
}
